{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.7.4 (default, Aug  9 2019, 18:34:13) [MSC v.1915 64 bit (AMD64)]\n",
      "Scipy: 1.3.1\n",
      "numpy: 1.16.4\n",
      "matplotlib: 3.1.1\n",
      "pandas: 0.25.1\n",
      "sklearn: 0.22.2\n"
     ]
    }
   ],
   "source": [
    "#check the version of the libraries\n",
    "\n",
    "# Python\n",
    "import sys\n",
    "print('Python: {}'.format(sys.version))\n",
    "\n",
    "#Scipy\n",
    "import scipy\n",
    "print('Scipy: {}'.format(scipy.__version__))\n",
    "\n",
    "#numpy\n",
    "import numpy\n",
    "print('numpy: {}'.format(numpy.__version__))\n",
    "\n",
    "#matplotlib\n",
    "import matplotlib\n",
    "print('matplotlib: {}'.format(matplotlib.__version__))\n",
    "\n",
    "#pandas\n",
    "import pandas\n",
    "print('pandas: {}'.format(pandas.__version__))\n",
    "\n",
    "#scikit-learn\n",
    "import sklearn\n",
    "print('sklearn: {}'.format(sklearn.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "\n",
    "import pandas\n",
    "from pandas.plotting import scatter_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\"\n",
    "names = ['sepal-length', 'sepal-width', 'petal-length', 'petal-width', 'class']\n",
    "\n",
    "# Using pandas to load the data\n",
    "dataset = pandas.read_csv( url, names=names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 5)\n"
     ]
    }
   ],
   "source": [
    "# Total number of rows and colums of the given dataset. Output will be (rows, colums)\n",
    "\n",
    "print(dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    sepal-length  sepal-width  petal-length  petal-width        class\n",
      "0            5.1          3.5           1.4          0.2  Iris-setosa\n",
      "1            4.9          3.0           1.4          0.2  Iris-setosa\n",
      "2            4.7          3.2           1.3          0.2  Iris-setosa\n",
      "3            4.6          3.1           1.5          0.2  Iris-setosa\n",
      "4            5.0          3.6           1.4          0.2  Iris-setosa\n",
      "5            5.4          3.9           1.7          0.4  Iris-setosa\n",
      "6            4.6          3.4           1.4          0.3  Iris-setosa\n",
      "7            5.0          3.4           1.5          0.2  Iris-setosa\n",
      "8            4.4          2.9           1.4          0.2  Iris-setosa\n",
      "9            4.9          3.1           1.5          0.1  Iris-setosa\n",
      "10           5.4          3.7           1.5          0.2  Iris-setosa\n",
      "11           4.8          3.4           1.6          0.2  Iris-setosa\n",
      "12           4.8          3.0           1.4          0.1  Iris-setosa\n",
      "13           4.3          3.0           1.1          0.1  Iris-setosa\n",
      "14           5.8          4.0           1.2          0.2  Iris-setosa\n",
      "15           5.7          4.4           1.5          0.4  Iris-setosa\n",
      "16           5.4          3.9           1.3          0.4  Iris-setosa\n",
      "17           5.1          3.5           1.4          0.3  Iris-setosa\n",
      "18           5.7          3.8           1.7          0.3  Iris-setosa\n",
      "19           5.1          3.8           1.5          0.3  Iris-setosa\n",
      "20           5.4          3.4           1.7          0.2  Iris-setosa\n",
      "21           5.1          3.7           1.5          0.4  Iris-setosa\n",
      "22           4.6          3.6           1.0          0.2  Iris-setosa\n",
      "23           5.1          3.3           1.7          0.5  Iris-setosa\n",
      "24           4.8          3.4           1.9          0.2  Iris-setosa\n",
      "25           5.0          3.0           1.6          0.2  Iris-setosa\n",
      "26           5.0          3.4           1.6          0.4  Iris-setosa\n",
      "27           5.2          3.5           1.5          0.2  Iris-setosa\n",
      "28           5.2          3.4           1.4          0.2  Iris-setosa\n",
      "29           4.7          3.2           1.6          0.2  Iris-setosa\n"
     ]
    }
   ],
   "source": [
    "# To print the first thirty instances\n",
    "\n",
    "print(dataset.head(30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     sepal-length  sepal-width  petal-length  petal-width           class\n",
      "120           6.9          3.2           5.7          2.3  Iris-virginica\n",
      "121           5.6          2.8           4.9          2.0  Iris-virginica\n",
      "122           7.7          2.8           6.7          2.0  Iris-virginica\n",
      "123           6.3          2.7           4.9          1.8  Iris-virginica\n",
      "124           6.7          3.3           5.7          2.1  Iris-virginica\n",
      "125           7.2          3.2           6.0          1.8  Iris-virginica\n",
      "126           6.2          2.8           4.8          1.8  Iris-virginica\n",
      "127           6.1          3.0           4.9          1.8  Iris-virginica\n",
      "128           6.4          2.8           5.6          2.1  Iris-virginica\n",
      "129           7.2          3.0           5.8          1.6  Iris-virginica\n",
      "130           7.4          2.8           6.1          1.9  Iris-virginica\n",
      "131           7.9          3.8           6.4          2.0  Iris-virginica\n",
      "132           6.4          2.8           5.6          2.2  Iris-virginica\n",
      "133           6.3          2.8           5.1          1.5  Iris-virginica\n",
      "134           6.1          2.6           5.6          1.4  Iris-virginica\n",
      "135           7.7          3.0           6.1          2.3  Iris-virginica\n",
      "136           6.3          3.4           5.6          2.4  Iris-virginica\n",
      "137           6.4          3.1           5.5          1.8  Iris-virginica\n",
      "138           6.0          3.0           4.8          1.8  Iris-virginica\n",
      "139           6.9          3.1           5.4          2.1  Iris-virginica\n",
      "140           6.7          3.1           5.6          2.4  Iris-virginica\n",
      "141           6.9          3.1           5.1          2.3  Iris-virginica\n",
      "142           5.8          2.7           5.1          1.9  Iris-virginica\n",
      "143           6.8          3.2           5.9          2.3  Iris-virginica\n",
      "144           6.7          3.3           5.7          2.5  Iris-virginica\n",
      "145           6.7          3.0           5.2          2.3  Iris-virginica\n",
      "146           6.3          2.5           5.0          1.9  Iris-virginica\n",
      "147           6.5          3.0           5.2          2.0  Iris-virginica\n",
      "148           6.2          3.4           5.4          2.3  Iris-virginica\n",
      "149           5.9          3.0           5.1          1.8  Iris-virginica\n"
     ]
    }
   ],
   "source": [
    "# To print the last 30 instances\n",
    "\n",
    "print(dataset.tail(30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       sepal-length  sepal-width  petal-length  petal-width\n",
      "count    150.000000   150.000000    150.000000   150.000000\n",
      "mean       5.843333     3.054000      3.758667     1.198667\n",
      "std        0.828066     0.433594      1.764420     0.763161\n",
      "min        4.300000     2.000000      1.000000     0.100000\n",
      "25%        5.100000     2.800000      1.600000     0.300000\n",
      "50%        5.800000     3.000000      4.350000     1.300000\n",
      "75%        6.400000     3.300000      5.100000     1.800000\n",
      "max        7.900000     4.400000      6.900000     2.500000\n"
     ]
    }
   ],
   "source": [
    "# Print all the related information of the dataset\n",
    "\n",
    "print(dataset.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.843333333333335\n"
     ]
    }
   ],
   "source": [
    "# I can access them by each column\n",
    "\n",
    "print(dataset['sepal-length'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class\n",
      "Iris-setosa        50\n",
      "Iris-versicolor    50\n",
      "Iris-virginica     50\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Number of instances for each class\n",
    "\n",
    "print(dataset.groupby('class').size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualization using plotting\n",
    "# Univariate visulization\n",
    "\n",
    "\n",
    "dataset.plot(kind= 'box', subplots = True, layout = (2, 2), sharex = False, sharey = False)\n",
    "\n",
    "## If we had used (4, 4) instead of (2, 2) then the plot would be shown in one row\n",
    "## Why are we using sharex and sharey?\n",
    "## -> If they are true, they will give us a cluttered visualization. Using the value of \n",
    "## x and y, they are showing how the values are scattered within a specific limit\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To show the histogram of each portion of data\n",
    "\n",
    "dataset.hist()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multivariate visualization\n",
    "\n",
    "scatter_matrix(dataset)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate some algorithm and estimate accuracy based on some unseen data\n",
    "\n",
    "# Create a validation dataset\n",
    "## Why do we need a validation dataset?\n",
    "## -> To know the model we created is good\n",
    "\n",
    "# Split the data so that we can use a part to train the model, another part will be for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the dataset\n",
    "\n",
    "array = dataset.values\n",
    "X = array[:, 0:4]\n",
    "Y = array[:, 4]\n",
    "\n",
    "validation_size = 0.20  # To use 20% of total data as validation data\n",
    "seed = 6   # We use seed to randomize the data for train and validation. To keep the same randomness\n",
    "\n",
    "\n",
    "## We will select the model based on the following method\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = model_selection.train_test_split(X, Y, test_size = validation_size, random_state = seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 6\n",
    "scoring = 'accuracy'  # Metric of accuracy to train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Asus\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Asus\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Asus\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Asus\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\model_selection\\_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.950000 (0.076376)\n",
      "LDA: 0.975000 (0.038188)\n",
      "KNN: 0.958333 (0.055902)\n",
      "CART: 0.933333 (0.072648)\n",
      "NB: 0.966667 (0.055277)\n",
      "SVM: 0.950000 (0.076376)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\model_selection\\_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n",
      "C:\\Users\\Asus\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\model_selection\\_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n",
      "C:\\Users\\Asus\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\model_selection\\_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n",
      "C:\\Users\\Asus\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\model_selection\\_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    }
   ],
   "source": [
    "# Building the model\n",
    "# Spot check algorithms\n",
    "\n",
    "models = []\n",
    "models.append(('LR', LogisticRegression()))\n",
    "models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('CART', DecisionTreeClassifier()))\n",
    "models.append(('NB', GaussianNB()))\n",
    "models.append(('SVM',SVC()))\n",
    "\n",
    "\n",
    "# Evaluate each model in turn\n",
    "\n",
    "results = []\n",
    "names = []\n",
    "\n",
    "\n",
    "## The data will divided into 10 parts( 10 fold cross validation)\n",
    "## for each iteration. And then one part will be used for validation, the other nine\n",
    "## parts will be used for training. That's the the model will be trained.\n",
    "## Then the information will be saved in models[] array for each algorithm.\n",
    "\n",
    "for name, model in models:\n",
    "    kfold = model_selection.KFold(n_splits=10, random_state=seed)\n",
    "    cv_results = model_selection.cross_val_score(model, X_train, Y_train, cv=kfold, scoring=scoring)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
